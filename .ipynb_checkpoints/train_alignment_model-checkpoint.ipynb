{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69001e60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T08:41:54.587780Z",
     "start_time": "2021-09-03T08:41:53.454898Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as model\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms,datasets\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe94305b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T08:41:54.886787Z",
     "start_time": "2021-09-03T08:41:54.589930Z"
    }
   },
   "outputs": [],
   "source": [
    "Model = timm.create_model('resnet18', pretrained=True, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba612b12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T08:41:54.943240Z",
     "start_time": "2021-09-03T08:41:54.888475Z"
    }
   },
   "outputs": [],
   "source": [
    "class load_data(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.img_list = glob.glob(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.abspath(img_name)\n",
    "        ret_img = cv2.imread(img_name)\n",
    "        \n",
    "        # JSON 파일 경로 설정\n",
    "        base_name = os.path.basename(img_name)\n",
    "        label_name = base_name.replace(\".jpg\", \".json\")\n",
    "        label_file = os.path.join(os.path.dirname(img_name), label_name)\n",
    "\n",
    "        # JSON 파일에서 좌표 읽어오기\n",
    "        with open(label_file, 'r', encoding='utf-8') as f:\n",
    "            label_data = json.load(f)\n",
    "        points = label_data['shapes'][0]['points']\n",
    "        ret_coord = np.array(points).flatten()\n",
    "\n",
    "        tp = random.randint(1, 5)  # shearing 관련\n",
    "        tp2 = random.randint(1, 4) # brightness 관련\n",
    "\n",
    "        # shear 변환\n",
    "        if tp == 1:\n",
    "            ret_img, ret_coord = self.shear_y1(ret_img, ret_coord)\n",
    "        elif tp == 2:\n",
    "            ret_img, ret_coord = self.shear_y2(ret_img, ret_coord)\n",
    "        elif tp == 3:\n",
    "            ret_img, ret_coord = self.shear_x1(ret_img, ret_coord)\n",
    "        elif tp == 4:\n",
    "            ret_img, ret_coord = self.shear_x2(ret_img, ret_coord)\n",
    "        else:\n",
    "            ret_img, ret_coord = self.original(ret_img, ret_coord)\n",
    "\n",
    "        ret_img = cv2.resize(ret_img, dsize=(128, 128))\n",
    "\n",
    "        # brightness augmentation\n",
    "        if tp2 == 1:\n",
    "            pass\n",
    "        elif tp2 == 2:\n",
    "            rnd_b = int(random.uniform(0, 50))\n",
    "            array = np.full(ret_img.shape, (rnd_b, rnd_b, rnd_b), dtype=np.uint8)\n",
    "            ret_img = cv2.add(ret_img, array)\n",
    "        elif tp2 == 3:\n",
    "            rnd_b = int(random.uniform(0, 60))\n",
    "            array = np.full(ret_img.shape, (rnd_b, rnd_b, rnd_b), dtype=np.uint8)\n",
    "            ret_img = cv2.subtract(ret_img, array)\n",
    "        else:\n",
    "            rnd_cover = int(random.uniform(54, 74))\n",
    "            rnd_step = int(random.uniform(13, 50))\n",
    "            rnd_tilt = int(random.randint(-1, 1))\n",
    "\n",
    "            mask_cover = rnd_cover\n",
    "            mask = np.zeros(ret_img.shape[0:2], dtype=np.uint8)\n",
    "\n",
    "            for col in range(mask.shape[1]):\n",
    "                for row in range(mask.shape[0]):\n",
    "                    if row <= mask_cover:\n",
    "                        mask[row][col] = 255\n",
    "                if (col + 1) % rnd_step == 0:\n",
    "                    mask_cover = mask_cover + rnd_tilt\n",
    "\n",
    "            rnd_b = int(random.uniform(0, 50))\n",
    "            array = np.full(ret_img.shape, (rnd_b, rnd_b, rnd_b), dtype=np.uint8)\n",
    "            shadowed = cv2.subtract(ret_img, array, mask=mask)\n",
    "            for row in range(shadowed.shape[0]):\n",
    "                for col in range(shadowed.shape[1]):\n",
    "                    if shadowed[row][col][0] == 0:\n",
    "                        shadowed[row][col] = ret_img[row][col]\n",
    "            ret_img = shadowed\n",
    "\n",
    "        ret_img = ret_img / 255.0\n",
    "        ret_coord = np.array(ret_coord)\n",
    "        ret_img = ret_img.transpose((2, 0, 1))\n",
    "\n",
    "        return ret_img, ret_coord, tp\n",
    "\n",
    "            \n",
    "    ########################################################################################################\n",
    "    def visualization(self, input_img, coord, color=(0, 0, 255)):\n",
    "        h, w = input_img.shape[:2]\n",
    "        coord_list = [(int(w * coord[0]), int(h * coord[1])),\n",
    "                      (int(w * coord[2]), int(h * coord[3])),\n",
    "                      (int(w * coord[4]), int(h * coord[5])),\n",
    "                      (int(w * coord[6]), int(h * coord[7]))]\n",
    "        return coord_list\n",
    "    ########################################################################################################\n",
    "    def shear_y1(self, input_img, ret_coord):\n",
    "        src = input_img\n",
    "        h, w = src.shape[:2]\n",
    "        # shear 주는 정도\n",
    "        degree = random.uniform(0,0.5)\n",
    "        degree = round(degree, 2)\n",
    "        #image shearing\n",
    "        affy =  np.array([[1, 0, 0],[degree, 1, 0]], dtype=np.float32)\n",
    "        dsty = cv2.warpAffine(src, affy, (w, h+ int(w * degree)))\n",
    "        # 좌표 shearing\n",
    "        hw = np.array([[w, 0],[0,h]])\n",
    "        ret_coord = np.reshape(ret_coord, (4,2))\n",
    "        r = np.dot(ret_coord, hw)\n",
    "        nh, nw = dsty.shape[:2]\n",
    "        r = [[r[0][0],r[0][1]+r[0][0]*degree], [r[1][0],r[1][1]+r[1][0]*degree], [r[2][0],r[2][1]+r[2][0]*degree], [r[3][0],r[3][1]+r[3][0]*degree]]\n",
    "        r = [[r[0][0]/nw,r[0][1]/nh], [r[1][0]/nw,r[1][1]/nh], [r[2][0]/nw,r[2][1]/nh], [r[3][0]/nw,r[3][1]/nh]]\n",
    "        ret_coord2 = np.array([r[0][0],r[0][1],r[1][0],r[1][1],r[2][0],r[2][1],r[3][0],r[3][1]])\n",
    "        coord = self.visualization(dsty, ret_coord2)\n",
    "        coord_x = []\n",
    "        coord_y = []\n",
    "        for i in coord:\n",
    "            coord_x.append(i[0])\n",
    "            coord_y.append(i[1])\n",
    "        min_x = min(coord_x);min_y = min(coord_y)\n",
    "        max_x = max(coord_x);max_y = max(coord_y)\n",
    "        # cropped image의 padding\n",
    "        pad_xr = nw*(random.uniform(0.01, 0.03))\n",
    "        pad_xl = nw*(random.uniform(0.01, 0.03))\n",
    "        pad_yu = nh*(random.uniform(0.005, 0.015))\n",
    "        pad_yd = nh*(random.uniform(0.005, 0.015))\n",
    "    \n",
    "        cropped_img = dsty[int(min_y-pad_yu): int(min_y-pad_yu + max_y-min_y+pad_yu+pad_yd), int(min_x-pad_xl): int(min_x-pad_xl + max_x-min_x+pad_xr+pad_xl)]\n",
    "    \n",
    "        coord_x = list(map(lambda x: x -int(min_x-pad_xl), coord_x))\n",
    "        coord_y = list(map(lambda x: x- int(min_y-pad_yu), coord_y))\n",
    "        new_coord = []\n",
    "        h2, w2 = cropped_img.shape[:2]\n",
    "        for i in range(4):\n",
    "            new_coord.append(coord_x[i]/w2)\n",
    "            new_coord.append(coord_y[i]/h2)\n",
    "        return cropped_img, new_coord\n",
    "    ########################################################################################################\n",
    "    def shear_y2(self, input_img, ret_coord):\n",
    "        src = input_img\n",
    "        h, w = src.shape[:2]\n",
    "        # shear 주는 정도\n",
    "        degree = random.uniform(-0.5,0)\n",
    "        degree = round(degree, 2)\n",
    "        # image shearing\n",
    "        affy =  np.array([[1, 0, 0],[degree, 1, -degree*w]], dtype=np.float32)\n",
    "        degree = -degree\n",
    "        dsty = cv2.warpAffine(src, affy, (w, h+ int(w * degree)))\n",
    "        # 좌표 shearing\n",
    "        hw = np.array([[w, 0],[0,h]])\n",
    "        ret_coord = np.reshape(ret_coord, (4,2))\n",
    "        nh, nw = dsty.shape[:2]\n",
    "        degree = -degree\n",
    "        r = np.dot(ret_coord, hw)\n",
    "        r = [[r[0][0],r[0][1]+r[0][0]*degree-degree*w], [r[1][0],r[1][1]+r[1][0]*degree-degree*w], [r[2][0],r[2][1]+r[2][0]*degree-degree*w], [r[3][0],r[3][1]+r[3][0]*degree-degree*w]]\n",
    "        r = [[r[0][0]/nw,r[0][1]/nh], [r[1][0]/nw,r[1][1]/nh], [r[2][0]/nw,r[2][1]/nh], [r[3][0]/nw,r[3][1]/nh]]\n",
    "        ret_coord2 = np.array([r[0][0],r[0][1],r[1][0],r[1][1],r[2][0],r[2][1],r[3][0],r[3][1]])\n",
    "        #print(ret_coord2)\n",
    "        coord = self.visualization(dsty, ret_coord2)\n",
    "        coord_x = []\n",
    "        coord_y = []\n",
    "        for i in coord:\n",
    "            coord_x.append(i[0])\n",
    "            coord_y.append(i[1])\n",
    "        min_x = min(coord_x);min_y = min(coord_y)\n",
    "        max_x = max(coord_x);max_y = max(coord_y)\n",
    "       # cropped image의 padding\n",
    "        pad_xr = nw*(random.uniform(0.01, 0.03))\n",
    "        pad_xl = nw*(random.uniform(0.01, 0.03))\n",
    "        pad_yu = nh*(random.uniform(0.005, 0.015))\n",
    "        pad_yd = nh*(random.uniform(0.005, 0.015))\n",
    "        cropped_img = dsty[int(min_y-pad_yu): int(min_y-pad_yu + max_y-min_y+pad_yu+pad_yd), int(min_x-pad_xl): int(min_x-pad_xl + max_x-min_x+pad_xr+pad_xl)]\n",
    "        coord_x = list(map(lambda x: x -int(min_x-pad_xl), coord_x))\n",
    "        coord_y = list(map(lambda x: x- int(min_y-pad_yu), coord_y))\n",
    "        new_coord = []\n",
    "        h2, w2 = cropped_img.shape[:2]\n",
    "        for i in range(4):\n",
    "            new_coord.append(coord_x[i]/w2)\n",
    "            new_coord.append(coord_y[i]/h2)\n",
    "        return cropped_img, new_coord\n",
    "    ########################################################################################################\n",
    "    def shear_x1(self, input_img, ret_coord):\n",
    "        src = input_img\n",
    "        h,w = src.shape[:2]\n",
    "        # shear 주는 정도\n",
    "        degree = random.uniform(0,0.5)\n",
    "        degree = round(degree, 2)\n",
    "        # image shearing\n",
    "        affx =  np.array([[1, degree, 0],[0, 1, 0]], dtype=np.float32)\n",
    "        dstx = cv2.warpAffine(src, affx, (w+ int(h * degree), h))\n",
    "        # 좌표 shearing\n",
    "        hw = np.array([[w, 0],[0,h]])\n",
    "        ret_coord = np.reshape(ret_coord, (4,2))\n",
    "        nh, nw = dstx.shape[:2]\n",
    "        r = np.dot(ret_coord, hw)\n",
    "        r = [[r[0][0]+r[0][1]*degree,r[0][1]], [r[1][0]+r[1][1]*degree,r[1][1]], [r[2][0]+r[2][1]*degree,r[2][1]], [r[3][0]+r[3][1]*degree,r[3][1]]]\n",
    "        r = [[r[0][0]/nw,r[0][1]/nh], [r[1][0]/nw,r[1][1]/nh], [r[2][0]/nw,r[2][1]/nh], [r[3][0]/nw,r[3][1]/nh]]\n",
    "        ret_coord2 = np.array([r[0][0],r[0][1],r[1][0],r[1][1],r[2][0],r[2][1],r[3][0],r[3][1]])\n",
    "        coord = self.visualization(dstx, ret_coord2)\n",
    "        coord_x = []\n",
    "        coord_y = []\n",
    "        for i in coord:\n",
    "            coord_x.append(i[0])\n",
    "            coord_y.append(i[1])\n",
    "        min_x = min(coord_x);min_y = min(coord_y)\n",
    "        max_x = max(coord_x);max_y = max(coord_y)\n",
    "        # cropped image의 padding\n",
    "        pad_xr = nw*(random.uniform(0.01, 0.03))\n",
    "        pad_xl = nw*(random.uniform(0.01, 0.03))\n",
    "        pad_yu = nh*(random.uniform(0.005, 0.015))\n",
    "        pad_yd = nh*(random.uniform(0.005, 0.015))\n",
    "        cropped_img = dstx[int(min_y-pad_yu): int(min_y-pad_yu + max_y-min_y+pad_yu+pad_yd), int(min_x-pad_xl): int(min_x-pad_xl + max_x-min_x+pad_xr+pad_xl)]\n",
    "        coord_x = list(map(lambda x: x -int(min_x-pad_xl), coord_x))\n",
    "        coord_y = list(map(lambda x: x- int(min_y-pad_yu), coord_y))\n",
    "        new_coord = []\n",
    "        h2, w2 = cropped_img.shape[:2]\n",
    "        for i in range(4):\n",
    "            new_coord.append(coord_x[i]/w2)\n",
    "            new_coord.append(coord_y[i]/h2)\n",
    "        return cropped_img, new_coord\n",
    "    ########################################################################################################\n",
    "    def shear_x2(self, input_img, ret_coord):\n",
    "        src = input_img\n",
    "        h, w = src.shape[:2]\n",
    "        # shear 주는 정도\n",
    "        degree = random.uniform(-0.5,0)\n",
    "        degree = round(degree, 2)\n",
    "        # image shearing\n",
    "        affx =  np.array([[1, degree, -degree*h],[0, 1, 0]], dtype=np.float32)\n",
    "        degree = -degree\n",
    "        dstx = cv2.warpAffine(src, affx, (w+ int(h * degree), h))\n",
    "        # 좌표 shearing\n",
    "        hw = np.array([[w, 0],[0,h]])\n",
    "        ret_coord = np.reshape(ret_coord, (4,2))\n",
    "        nh, nw = dstx.shape[:2]\n",
    "        degree = -degree\n",
    "        r = np.dot(ret_coord, hw)\n",
    "        r = [[r[0][0]+r[0][1]*degree -degree*h,r[0][1]], [r[1][0]+r[1][1]*degree -degree*h,r[1][1]], [r[2][0]+r[2][1]*degree -degree*h,r[2][1]], [r[3][0]+r[3][1]*degree -degree*h,r[3][1]]]\n",
    "        r = [[r[0][0]/nw,r[0][1]/nh], [r[1][0]/nw,r[1][1]/nh], [r[2][0]/nw,r[2][1]/nh], [r[3][0]/nw,r[3][1]/nh]]\n",
    "        ret_coord2 = np.array([r[0][0],r[0][1],r[1][0],r[1][1],r[2][0],r[2][1],r[3][0],r[3][1]])\n",
    "        coord = self.visualization(dstx, ret_coord2)\n",
    "        coord_x = []\n",
    "        coord_y = []\n",
    "        for i in coord:\n",
    "            coord_x.append(i[0])\n",
    "            coord_y.append(i[1])\n",
    "        min_x = min(coord_x);min_y = min(coord_y)\n",
    "        max_x = max(coord_x);max_y = max(coord_y)\n",
    "        # cropped image의 padding\n",
    "        pad_xr = nw*(random.uniform(0.01, 0.03))\n",
    "        pad_xl = nw*(random.uniform(0.01, 0.03))\n",
    "        pad_yu = nh*(random.uniform(0.005, 0.015))\n",
    "        pad_yd = nh*(random.uniform(0.005, 0.015))\n",
    "        cropped_img = dstx[int(min_y-pad_yu): int(min_y-pad_yu + max_y-min_y+pad_yu+pad_yd), int(min_x-pad_xl): int(min_x-pad_xl + max_x-min_x+pad_xr+pad_xl)]\n",
    "        coord_x = list(map(lambda x: x -int(min_x-pad_xl), coord_x))\n",
    "        coord_y = list(map(lambda x: x- int(min_y-pad_yu), coord_y))\n",
    "        new_coord = []\n",
    "        h2, w2 = cropped_img.shape[:2]\n",
    "        for i in range(4):\n",
    "            new_coord.append(coord_x[i]/w2)\n",
    "            new_coord.append(coord_y[i]/h2)\n",
    "        return cropped_img, new_coord\n",
    "    ########################################################################################################\n",
    "    def original(self, input_img, ret_coord):\n",
    "        src = input_img\n",
    "        h, w = src.shape[:2]\n",
    "        coord = self.visualization(src, ret_coord)\n",
    "        coord_x = []\n",
    "        coord_y = []\n",
    "        for i in coord:\n",
    "            coord_x.append(i[0])\n",
    "            coord_y.append(i[1])\n",
    "        min_x = min(coord_x);min_y = min(coord_y)\n",
    "        max_x = max(coord_x);max_y = max(coord_y)\n",
    "        # cropped image의 padding\n",
    "        pad_xr = w*(random.uniform(0.01, 0.03))\n",
    "        pad_xl = w*(random.uniform(0.01, 0.03))\n",
    "        pad_yu = h*(random.uniform(0.005, 0.015))\n",
    "        pad_yd = h*(random.uniform(0.005, 0.015))\n",
    "        cropped_img = src[int(min_y-pad_yu): int(min_y-pad_yu + max_y-min_y+pad_yu+pad_yd), int(min_x-pad_xl): int(min_x-pad_xl + max_x-min_x+pad_xr+pad_xl)]\n",
    "        coord_x = list(map(lambda x: x -int(min_x-pad_xl), coord_x))\n",
    "        coord_y = list(map(lambda x: x- int(min_y-pad_yu), coord_y))\n",
    "        new_coord = []\n",
    "        h2, w2 = cropped_img.shape[:2]\n",
    "        for i in range(4):\n",
    "            new_coord.append(coord_x[i]/w2)\n",
    "            new_coord.append(coord_y[i]/h2)\n",
    "        return cropped_img, new_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab0457cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T08:41:54.961880Z",
     "start_time": "2021-09-03T08:41:54.944480Z"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def visualization(img: torch.Tensor, coord:torch.Tensor, color=(0, 255, 0)):\n",
    "        input_img = np.array((img.cpu().detach().numpy().transpose((1, 2, 0)) * 255.0)).astype(np.uint8) # (128, 128, 3)\n",
    "        coord = coord.cpu().detach().numpy() # (8,)\n",
    "    \n",
    "    \n",
    "        coord_list = [(int(128 * coord[0]), int(128 * coord[1])),\n",
    "                      (int(coord[2] * 128), int(128 * coord[3])),\n",
    "                      (int(128 * coord[4]), int(128 * coord[5])),\n",
    "                      (int(128 * coord[6]), int(128 * coord[7]))]\n",
    "    \n",
    "        image = cv2.cvtColor(np.array(input_img), cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.line(image, coord_list[0], coord_list[1], color=color)\n",
    "        img = cv2.line(img, coord_list[1], coord_list[2], color=color)\n",
    "        img = cv2.line(img, coord_list[2], coord_list[3], color=color)\n",
    "        img = cv2.line(img, coord_list[3], coord_list[0], color=color)\n",
    "        \n",
    "    \n",
    "        print(\"visualizing...\")\n",
    "        plt.imshow(img[:,:,::-1])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3f3d3ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T08:41:54.977669Z",
     "start_time": "2021-09-03T08:41:54.963327Z"
    }
   },
   "outputs": [],
   "source": [
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.img_list = glob.glob(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.abspath(img_name)\n",
    "        base_name = os.path.basename(img_name)\n",
    "        label_name = base_name.replace(\".jpg\", \".json\")\n",
    "        label_file = os.path.join(os.path.dirname(img_name), label_name)\n",
    "\n",
    "        # JSON 파일에서 좌표를 읽어오기\n",
    "        with open(label_file, 'r', encoding='utf-8') as f:\n",
    "            label_data = json.load(f)\n",
    "        \n",
    "        points = label_data['shapes'][0]['points']\n",
    "        ret_coord = np.array(points).flatten()  # 좌표를 일렬로 변환\n",
    "\n",
    "        # 이미지 로드 및 전처리\n",
    "        ret_img = cv2.imread(img_name)\n",
    "        ret_img, ret_coord = self.original(ret_img, ret_coord)\n",
    "        ret_img = cv2.resize(ret_img, (128, 128)) / 255.0\n",
    "        ret_img = ret_img.transpose((2, 0, 1))\n",
    "\n",
    "        return ret_img, ret_coord\n",
    "\n",
    "    def original(self, input_img, ret_coord):\n",
    "        h, w = input_img.shape[:2]\n",
    "        coord_x = ret_coord[::2]  # x 좌표\n",
    "        coord_y = ret_coord[1::2]  # y 좌표\n",
    "        min_x, min_y = np.min(coord_x), np.min(coord_y)\n",
    "        max_x, max_y = np.max(coord_x), np.max(coord_y)\n",
    "\n",
    "        # 패딩 추가\n",
    "        pad_xr = w * (random.uniform(0.01, 0.03))\n",
    "        pad_xl = w * (random.uniform(0.01, 0.03))\n",
    "        pad_yu = h * (random.uniform(0.005, 0.015))\n",
    "        pad_yd = h * (random.uniform(0.005, 0.015))\n",
    "\n",
    "        # 이미지 자르기\n",
    "        cropped_img = input_img[int(min_y - pad_yu): int(max_y + pad_yd),\n",
    "                                int(min_x - pad_xl): int(max_x + pad_xr)]\n",
    "        \n",
    "        coord_x = list(map(lambda x: x - int(min_x - pad_xl), coord_x))\n",
    "        coord_y = list(map(lambda x: x - int(min_y - pad_yu), coord_y))\n",
    "\n",
    "        new_coord = []\n",
    "        h2, w2 = cropped_img.shape[:2]\n",
    "        for x, y in zip(coord_x, coord_y):\n",
    "            new_coord.append(x / w2)\n",
    "            new_coord.append(y / h2)\n",
    "        \n",
    "        return cropped_img, new_coord \n",
    "\n",
    "        \n",
    "    def visualization(self, input_img, coord, color=(0, 0, 255)):\n",
    "        h, w = input_img.shape[:2]\n",
    "        coord_list = [(int(w * coord[0]), int(h * coord[1])),\n",
    "                      (int(w * coord[2]), int(h * coord[3])),\n",
    "                      (int(w * coord[4]), int(h * coord[5])),\n",
    "                      (int(w * coord[6]), int(h * coord[7]))]\n",
    "        return coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d210fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T08:41:55.000800Z",
     "start_time": "2021-09-03T08:41:54.978857Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = './data/train/*.jpg'\n",
    "test_path =  './data/val/*.jpg'\n",
    "train_dataset = load_data(train_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True, num_workers = 0, pin_memory=True)\n",
    "\n",
    "test_dataset = ValidationDataset(test_path)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers = 0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a4d70dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T08:41:59.001558Z",
     "start_time": "2021-09-03T08:41:55.002040Z"
    }
   },
   "outputs": [],
   "source": [
    "# L1Loss\n",
    "\n",
    "epoch = 256\n",
    "device = torch.device('cuda')\n",
    "Model.cuda()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(Model.parameters(), lr=0.05, momentum=0.9, nesterov=True)\n",
    "x = torch.randn(64, 3, 128, 128, requires_grad = True).cuda() #dummy input\n",
    "best = 10000\n",
    "count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8dd837f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T17:39:52.693735Z",
     "start_time": "2021-09-03T08:41:59.003419Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::Train::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'img_name' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::::Train::::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m Model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)):\n\u001b[0;32m      7\u001b[0m     data_x \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      8\u001b[0m     data_y \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[56], line 9\u001b[0m, in \u001b[0;36mload_data.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m----> 9\u001b[0m     img_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[43mimg_name\u001b[49m)\n\u001b[0;32m     10\u001b[0m     ret_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_name)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# JSON 파일 경로 설정\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'img_name' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for ep in range(epoch):\n",
    "    avg_loss = AverageMeter()\n",
    "    # train\n",
    "    print(\"::::Train::::\")\n",
    "    Model.train()\n",
    "    for idx, i in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "        data_x = i[0].type(torch.float32).cuda()\n",
    "        data_y = i[1].type(torch.float32).cuda()\n",
    "        tp = i[2]\n",
    "        out = Model(data_x)\n",
    "        out = torch.sigmoid(out)\n",
    "        loss = criterion(out, data_y)\n",
    "        avg_loss.update(loss.item(), data_x.shape[0])\n",
    "        if ep in [1,2,3,4,5,6,7,10, 20, 30, 40, 50, 80, 100, 130, 150, 170, 190, 210, 230, 255] and idx == 0:\n",
    "            visualization(data_x[0], data_y[0], color=(0, 255, 0))\n",
    "            visualization(data_x[0], out[0], color=(0, 0, 255))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(avg_loss.avg)\n",
    "    print(\"::::Validation::::\")\n",
    "    # evaluation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    preds = torch.tensor([], dtype=torch.float).cuda()\n",
    "    gt = torch.tensor([], dtype=torch.float).cuda()\n",
    "    Model.eval()\n",
    "    with torch.no_grad():\n",
    "        # validation code\n",
    "        for idx, i in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            data_x = i[0].type(torch.float32).cuda() # (64, 3, 128, 128)\n",
    "            data_y = i[1].type(torch.float32).cuda() # (64, 8)\n",
    "            \n",
    "\n",
    "            out = Model(data_x) # (64, 8)\n",
    "            out = torch.sigmoid(out) \n",
    "            preds = torch.cat((preds, out), 0)\n",
    "            gt = torch.cat((gt, data_y), 0)\n",
    "            if ep in [1, 10, 20, 30, 40, 50, 80, 100, 130, 150, 170, 190, 210, 230, 255] and idx == 0:\n",
    "            \n",
    "                visualization(data_x[0], data_y[0], color=(0, 255, 0))\n",
    "                visualization(data_x[0], out[0], color=(0, 0, 255))\n",
    "\n",
    "        preds = preds.cpu().detach().numpy()\n",
    "        gt = gt.cpu().detach().numpy()\n",
    "        rmse = np.sqrt(mean_squared_error(preds, gt))\n",
    "\n",
    "    if best > rmse:\n",
    "        print('smaller rmse, saving model weights...')\n",
    "        print('best: ',best,'current rmse: ',rmse)\n",
    "        count += 1\n",
    "        best = rmse\n",
    "        \n",
    "        # save\n",
    "        p = './resnet18_best_random_shear/best'+str(count)+'.pth'\n",
    "        torch.save(Model,p)\n",
    "        torch.onnx.export(Model,\n",
    "                      x,\n",
    "                      \"./onnxfile/resnet18_best_random_shear.onnx\",\n",
    "                      export_params=True, \n",
    "                      opset_version=10, # onnx version\n",
    "                      do_constant_folding=True, \n",
    "                      input_names = ['input'],\n",
    "                      output_names = ['output'], \n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'}, \n",
    "                                    'output' : {0 : 'batch_size'}}) \n",
    "\n",
    "    print('epoch{0} end'.format(ep))\n",
    "    print('='*100)\n",
    "    \n",
    "    \n",
    "print('best : '+str(best))\n",
    "print('End')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179ed2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8ff8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f49ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8313dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c731f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dae1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
